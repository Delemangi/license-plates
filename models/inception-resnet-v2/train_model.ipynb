{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from glob import glob\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.applications import InceptionResNetV2\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.utils import Sequence\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = '../../dataset/images/*.png'\n",
    "annotations_path = '../../dataset/annotations/*.xml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(annotation, image):\n",
    "    xml = ET.parse(annotation)\n",
    "    info = xml.getroot().find('object').find('bndbox')\n",
    "    xmin = int(info.find('xmin').text)\n",
    "    ymin = int(info.find('ymin').text)\n",
    "    xmax = int(info.find('xmax').text)\n",
    "    ymax = int(info.find('ymax').text)\n",
    "\n",
    "    xmin = xmin / image.shape[1]\n",
    "    xmax = xmax / image.shape[1]\n",
    "    ymin = ymin / image.shape[0]\n",
    "    ymax = ymax / image.shape[0]\n",
    "\n",
    "    return np.array([xmin, ymin, xmax, ymax])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Sequence):\n",
    "    def __init__(self, images_path: str, annotations_path: str, start: float, end: float, batch_size: int = 32):\n",
    "        self.images_path = glob(images_path)\n",
    "        self.images_path = self.images_path[int(start * len(self.images_path)):int(end * len(self.images_path))]\n",
    "        self.annotations_path = glob(annotations_path)\n",
    "        self.annotations_path = self.annotations_path[int(start * len(self.annotations_path)):int(end * len(self.annotations_path))]\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.images_path) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        images = self.images_path[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        annotations = self.annotations_path[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        images = [cv2.imread(os.path.join('../../dataset/images', i)) for i in images]\n",
    "        annotations = [get_annotations(a, i) for a, i in zip(annotations, images)]\n",
    "        images = [cv2.resize(i, (224, 224)) / 255 for i in images]\n",
    "\n",
    "        return np.array(images), np.array(annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\Python\\license-plates\\models\\inception-resnet-v2\\train_model.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/Python/license-plates/models/inception-resnet-v2/train_model.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m Sequential()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/Python/license-plates/models/inception-resnet-v2/train_model.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39madd(InceptionResNetV2(weights\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mimagenet\u001b[39;49m\u001b[39m'\u001b[39;49m, include_top\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, input_shape\u001b[39m=\u001b[39;49m(\u001b[39m224\u001b[39;49m, \u001b[39m224\u001b[39;49m, \u001b[39m3\u001b[39;49m)))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/Python/license-plates/models/inception-resnet-v2/train_model.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39madd(Flatten())\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/Python/license-plates/models/inception-resnet-v2/train_model.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m500\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Stefan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\applications\\inception_resnet_v2.py:184\u001b[0m, in \u001b[0;36mInceptionResNetV2\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[39m# 20x block17 (Inception-ResNet-B block): 17 x 17 x 1088\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[39mfor\u001b[39;00m block_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m21\u001b[39m):\n\u001b[1;32m--> 184\u001b[0m   x \u001b[39m=\u001b[39m inception_resnet_block(\n\u001b[0;32m    185\u001b[0m       x, scale\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, block_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mblock17\u001b[39;49m\u001b[39m'\u001b[39;49m, block_idx\u001b[39m=\u001b[39;49mblock_idx)\n\u001b[0;32m    187\u001b[0m \u001b[39m# Mixed 7a (Reduction-B block): 8 x 8 x 2080\u001b[39;00m\n\u001b[0;32m    188\u001b[0m branch_0 \u001b[39m=\u001b[39m conv2d_bn(x, \u001b[39m256\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Stefan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\applications\\inception_resnet_v2.py:344\u001b[0m, in \u001b[0;36minception_resnet_block\u001b[1;34m(x, scale, block_type, block_idx, activation)\u001b[0m\n\u001b[0;32m    342\u001b[0m   branch_1 \u001b[39m=\u001b[39m conv2d_bn(x, \u001b[39m128\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m    343\u001b[0m   branch_1 \u001b[39m=\u001b[39m conv2d_bn(branch_1, \u001b[39m160\u001b[39m, [\u001b[39m1\u001b[39m, \u001b[39m7\u001b[39m])\n\u001b[1;32m--> 344\u001b[0m   branch_1 \u001b[39m=\u001b[39m conv2d_bn(branch_1, \u001b[39m192\u001b[39;49m, [\u001b[39m7\u001b[39;49m, \u001b[39m1\u001b[39;49m])\n\u001b[0;32m    345\u001b[0m   branches \u001b[39m=\u001b[39m [branch_0, branch_1]\n\u001b[0;32m    346\u001b[0m \u001b[39melif\u001b[39;00m block_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mblock8\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Stefan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\applications\\inception_resnet_v2.py:290\u001b[0m, in \u001b[0;36mconv2d_bn\u001b[1;34m(x, filters, kernel_size, strides, padding, activation, use_bias, name)\u001b[0m\n\u001b[0;32m    288\u001b[0m   bn_axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39mimage_data_format() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mchannels_first\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m3\u001b[39m\n\u001b[0;32m    289\u001b[0m   bn_name \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_bn\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 290\u001b[0m   x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39;49mBatchNormalization(axis\u001b[39m=\u001b[39;49mbn_axis, scale\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mbn_name)(x)\n\u001b[0;32m    291\u001b[0m \u001b[39mif\u001b[39;00m activation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    292\u001b[0m   ac_name \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_ac\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Stefan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Stefan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py:944\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[39m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[0;32m    940\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[0;32m    941\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\u001b[39mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[1;32m--> 944\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m    945\u001b[0m                                             input_list)\n\u001b[0;32m    947\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[0;32m    948\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
      "File \u001b[1;32mc:\\Users\\Stefan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py:2315\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   2310\u001b[0m     training_arg_passed_by_framework \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2312\u001b[0m \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[0;32m   2313\u001b[0m     layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value):\n\u001b[0;32m   2314\u001b[0m   \u001b[39m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[1;32m-> 2315\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_tensor_symbolic_call(\n\u001b[0;32m   2316\u001b[0m       inputs, input_masks, args, kwargs)\n\u001b[0;32m   2318\u001b[0m   \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mA layer\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39ms `call` method should return a \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2320\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mTensor or a list of Tensors, not None \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2321\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m(layer: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m).\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Stefan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py:2186\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m   2184\u001b[0m   \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(keras_tensor\u001b[39m.\u001b[39mKerasTensor, output_signature)\n\u001b[0;32m   2185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2186\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "File \u001b[1;32mc:\\Users\\Stefan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py:2213\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m   2204\u001b[0m call_fn \u001b[39m=\u001b[39m traceback_utils\u001b[39m.\u001b[39minject_argument_info_in_traceback(\n\u001b[0;32m   2205\u001b[0m     call_fn,\n\u001b[0;32m   2206\u001b[0m     object_name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlayer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   2208\u001b[0m \u001b[39m# We enter a scratch graph and build placeholder inputs inside of it that\u001b[39;00m\n\u001b[0;32m   2209\u001b[0m \u001b[39m# match the input args.\u001b[39;00m\n\u001b[0;32m   2210\u001b[0m \u001b[39m# We then call the layer inside of the scratch graph to identify the\u001b[39;00m\n\u001b[0;32m   2211\u001b[0m \u001b[39m# output signatures, then we build KerasTensors corresponding to those\u001b[39;00m\n\u001b[0;32m   2212\u001b[0m \u001b[39m# outputs.\u001b[39;00m\n\u001b[1;32m-> 2213\u001b[0m scratch_graph \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49mFuncGraph(\u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname) \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m_scratch_graph\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m   2214\u001b[0m \u001b[39mwith\u001b[39;00m scratch_graph\u001b[39m.\u001b[39mas_default():\n\u001b[0;32m   2215\u001b[0m   inputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   2216\u001b[0m       keras_tensor\u001b[39m.\u001b[39mkeras_tensor_to_placeholder, inputs)\n",
      "File \u001b[1;32mc:\\Users\\Stefan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:196\u001b[0m, in \u001b[0;36mFuncGraph.__init__\u001b[1;34m(self, name, collections, capture_by_value, structured_input_signature, structured_outputs)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m    168\u001b[0m              name,\n\u001b[0;32m    169\u001b[0m              collections\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    170\u001b[0m              capture_by_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    171\u001b[0m              structured_input_signature\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    172\u001b[0m              structured_outputs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    173\u001b[0m   \u001b[39m\"\"\"Construct a new FuncGraph.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \n\u001b[0;32m    175\u001b[0m \u001b[39m  The graph will inherit its graph key, collections, seed, and distribution\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39m      information.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m   \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m()\n\u001b[0;32m    197\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m name\n\u001b[0;32m    198\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Stefan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3168\u001b[0m, in \u001b[0;36mGraph.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reduced_shape_cache \u001b[39m=\u001b[39m {}\n\u001b[0;32m   3166\u001b[0m \u001b[39m# TODO(skyewm): fold as much of the above as possible into the C\u001b[39;00m\n\u001b[0;32m   3167\u001b[0m \u001b[39m# implementation\u001b[39;00m\n\u001b[1;32m-> 3168\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scoped_c_graph \u001b[39m=\u001b[39m c_api_util\u001b[39m.\u001b[39;49mScopedTFGraph()\n\u001b[0;32m   3169\u001b[0m \u001b[39m# The C API requires all ops to have shape functions. Disable this\u001b[39;00m\n\u001b[0;32m   3170\u001b[0m \u001b[39m# requirement (many custom ops do not have shape functions, and we don't\u001b[39;00m\n\u001b[0;32m   3171\u001b[0m \u001b[39m# want to break these existing cases).\u001b[39;00m\n\u001b[0;32m   3172\u001b[0m pywrap_tf_session\u001b[39m.\u001b[39mSetRequireShapeInferenceFns(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_graph, \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Stefan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\c_api_util.py:47\u001b[0m, in \u001b[0;36mScopedTFGraph.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 47\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph \u001b[39m=\u001b[39m c_api\u001b[39m.\u001b[39;49mTF_NewGraph()\n\u001b[0;32m     48\u001b[0m   \u001b[39m# Note: when we're destructing the global context (i.e when the process is\u001b[39;00m\n\u001b[0;32m     49\u001b[0m   \u001b[39m# terminating) we may have already deleted other modules. By capturing the\u001b[39;00m\n\u001b[0;32m     50\u001b[0m   \u001b[39m# DeleteGraph function here, we retain the ability to cleanly destroy the\u001b[39;00m\n\u001b[0;32m     51\u001b[0m   \u001b[39m# graph at shutdown, which satisfies leak checkers.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeleter \u001b[39m=\u001b[39m c_api\u001b[39m.\u001b[39mTF_DeleteGraph\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "6/6 [==============================] - 23s 1s/step - loss: 0.0888 - val_loss: 0.0752\n",
      "Epoch 2/15\n",
      "6/6 [==============================] - 4s 654ms/step - loss: 0.0390 - val_loss: 0.0394\n",
      "Epoch 3/15\n",
      "6/6 [==============================] - 4s 690ms/step - loss: 0.0164 - val_loss: 0.0285\n",
      "Epoch 4/15\n",
      "6/6 [==============================] - 4s 636ms/step - loss: 0.0081 - val_loss: 0.0232\n",
      "Epoch 5/15\n",
      "6/6 [==============================] - 4s 627ms/step - loss: 0.0048 - val_loss: 0.0219\n",
      "Epoch 6/15\n",
      "6/6 [==============================] - 4s 662ms/step - loss: 0.0031 - val_loss: 0.0228\n",
      "Epoch 7/15\n",
      "6/6 [==============================] - 4s 630ms/step - loss: 0.0026 - val_loss: 0.0199\n",
      "Epoch 8/15\n",
      "6/6 [==============================] - 4s 675ms/step - loss: 0.0014 - val_loss: 0.0212\n",
      "Epoch 9/15\n",
      "6/6 [==============================] - 5s 794ms/step - loss: 0.0011 - val_loss: 0.0200\n",
      "Epoch 10/15\n",
      "6/6 [==============================] - 5s 703ms/step - loss: 9.7459e-04 - val_loss: 0.0196\n",
      "Epoch 11/15\n",
      "6/6 [==============================] - 4s 746ms/step - loss: 6.2429e-04 - val_loss: 0.0192\n",
      "Epoch 12/15\n",
      "6/6 [==============================] - 4s 686ms/step - loss: 4.2498e-04 - val_loss: 0.0191\n",
      "Epoch 13/15\n",
      "6/6 [==============================] - 5s 655ms/step - loss: 2.6914e-04 - val_loss: 0.0196\n",
      "Epoch 14/15\n",
      "6/6 [==============================] - 4s 600ms/step - loss: 2.8766e-04 - val_loss: 0.0195\n",
      "Epoch 15/15\n",
      "6/6 [==============================] - 4s 596ms/step - loss: 2.3431e-04 - val_loss: 0.0192\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_dataset = Dataset(images_path, annotations_path, 0, 0.8, batch_size)\n",
    "val_dataset = Dataset(images_path, annotations_path, 0.8, 0.9, batch_size)\n",
    "\n",
    "model.compile(optimizer=Adam(1e-4), loss='mse')\n",
    "history = model.fit(x=train_dataset, epochs=15, batch_size=batch_size, validation_data=val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model_15.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d4145756fc1ff49eb402fff0fe48f1eeee4f832bb02e6b51f5a8ece64bc12c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
